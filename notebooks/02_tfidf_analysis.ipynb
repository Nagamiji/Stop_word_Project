{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "297aa556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d74f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess / normalize Khmer text\n",
    "\n",
    "def normalize_khmer_spaces(text):\n",
    "    \"\"\"Replace invisible spaces and normalize multiple spaces\"\"\"\n",
    "    text = text.replace('\\u200b', ' ')  # zero-width space\n",
    "    text = text.replace('\\xa0', ' ')    # non-breaking space\n",
    "    text = text.replace('\\u200c', ' ')  # zero-width non-joiner\n",
    "    text = text.replace('\\u200d', ' ')  # zero-width joiner\n",
    "    text = re.sub(r'\\s+', ' ', text)    # replace multiple spaces with single space\n",
    "    return text.strip()\n",
    "\n",
    "def load_documents(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        docs = [line.strip() for line in f if line.strip()]\n",
    "    # Normalize spaces\n",
    "    docs = [normalize_khmer_spaces(doc) for doc in docs]\n",
    "    return docs\n",
    "\n",
    "docs_with_sw = load_documents(\"dataset_with_stopwords.txt\")\n",
    "docs_without_sw = load_documents(\"dataset_remove_stopwords.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bbd29e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize documents (split by space)\n",
    "tokenized_docs_with_sw = [doc.split(\" \") for doc in docs_with_sw]\n",
    "tokenized_docs_without_sw = [doc.split(\" \") for doc in docs_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1540ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(doc_tokens):\n",
    "    \"\"\"Compute term frequency for a single document\"\"\"\n",
    "    tf = {}\n",
    "    word_count = Counter(doc_tokens)\n",
    "    total_words = len(doc_tokens)\n",
    "    for word, count in word_count.items():\n",
    "        tf[word] = count / total_words\n",
    "    return tf\n",
    "\n",
    "tf_docs_with_sw = [compute_tf(doc) for doc in tokenized_docs_with_sw]\n",
    "tf_docs_without_sw = [compute_tf(doc) for doc in tokenized_docs_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52e923db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Optimized IDF computation\n",
    "def compute_idf_fast(tokenized_docs):\n",
    "    \"\"\"Compute IDF using Counter (single pass, much faster)\"\"\"\n",
    "    N = len(tokenized_docs)\n",
    "    df_counter = Counter()\n",
    "\n",
    "    # Count in how many documents each word appears\n",
    "    for doc in tokenized_docs:\n",
    "        unique_words = set(doc)  # only count each word once per doc\n",
    "        df_counter.update(unique_words)\n",
    "\n",
    "    # Compute IDF\n",
    "    idf = {word: math.log(N / (df_counter[word] + 1)) for word in df_counter}\n",
    "    return idf\n",
    "\n",
    "idf_with_sw = compute_idf_fast(tokenized_docs_with_sw)\n",
    "idf_without_sw = compute_idf_fast(tokenized_docs_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c4f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tfidf(tf_doc, idf):\n",
    "    \"\"\"Compute TF-IDF for a single document\"\"\"\n",
    "    return {word: tf_value * idf.get(word, 0) for word, tf_value in tf_doc.items()}\n",
    "\n",
    "tfidf_docs_with_sw = [compute_tfidf(tf, idf_with_sw) for tf in tf_docs_with_sw]\n",
    "tfidf_docs_without_sw = [compute_tfidf(tf, idf_without_sw) for tf in tf_docs_without_sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f947b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words with stopwords (first doc):\n",
      "ឥណ្ឌា: 0.3013\n",
      "របៀបវារៈ: 0.1445\n",
      "ជ្រុងជ្រោយ: 0.1444\n",
      "ការធ្វើដំណើរ: 0.1366\n",
      "កិច្ចពិភាក្សា: 0.1366\n",
      "ការអញ្ជើញ: 0.1357\n",
      "សារៈសំខាន់: 0.1269\n",
      "សេចក្តីថ្លែងការណ៍: 0.1197\n",
      "ទាំងមូល: 0.1172\n",
      "ទស្សនកិច្ច: 0.1146\n",
      "\n",
      "Top words without stopwords (first doc):\n",
      "ឥណ្ឌា: 0.5214\n",
      "របៀបវារៈ: 0.2501\n",
      "ជ្រុងជ្រោយ: 0.2499\n",
      "ការធ្វើដំណើរ: 0.2364\n",
      "កិច្ចពិភាក្សា: 0.2364\n",
      "ការអញ្ជើញ: 0.2349\n",
      "សារៈសំខាន់: 0.2196\n",
      "សេចក្តីថ្លែងការណ៍: 0.2072\n",
      "ទាំងមូល: 0.2029\n",
      "ទស្សនកិច្ច: 0.1983\n"
     ]
    }
   ],
   "source": [
    "#  Memory-efficient: Get top N words per document\n",
    "def top_tfidf_words(tfidf_doc, top_n=10):\n",
    "    \"\"\"Return top N words and their TF-IDF scores\"\"\"\n",
    "    return sorted(tfidf_doc.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Example: top 10 words for first document\n",
    "print(\"Top words with stopwords (first doc):\")\n",
    "for w, s in top_tfidf_words(tfidf_docs_with_sw[0]):\n",
    "    print(f\"{w}: {s:.4f}\")\n",
    "\n",
    "print(\"\\nTop words without stopwords (first doc):\")\n",
    "for w, s in top_tfidf_words(tfidf_docs_without_sw[0]):\n",
    "    print(f\"{w}: {s:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad9db4",
   "metadata": {},
   "source": [
    "The TF-IDF scores increase for meaningful content words after removing stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8fc8efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words WITH stopwords (corpus-level):\n",
      "ឯកច្ឆន្ច: 6.6530\n",
      "អសុពលភាព: 6.6530\n",
      "ហ្សូអ៊ី: 5.5442\n",
      "គតេ: 4.4353\n",
      "ឣនុធម្មចារី: 3.6961\n",
      "វេទព្វជាតក: 3.6961\n",
      "កិម្បក្កជាតក: 3.6961\n",
      "សុទ្ធ់: 3.6961\n",
      "សីហធម្មជាតក: 3.6961\n",
      "កន្ថរ៉ា: 3.6961\n",
      "ហ្វហ: 3.6961\n",
      "វានរជាតក: 3.6961\n",
      "បច្ចុប្បន្នៈ: 3.6961\n",
      "ចូច: 3.6961\n",
      "ពុទ្ធារី: 3.6961\n",
      "វីតា: 3.6961\n",
      "ឧទាយិវគ្គ: 3.6961\n",
      "អត្ថទ: 3.6961\n",
      "ព្រះតន្តិ: 3.6961\n",
      "ព្រះតន្តី: 3.6961\n",
      "\n",
      "Top 20 words WITHOUT stopwords (corpus-level):\n",
      "អសុពលភាព: 11.0883\n",
      "ប្រូតូកាទុ: 11.0883\n",
      "ត្រូវៈ: 11.0883\n",
      "ឯកច្ឆន្ច: 8.3162\n",
      "អ្នកសង្កេតឃើញ: 5.5442\n",
      "ទៅកាន់ខ្សែភាពយន្ត: 5.5442\n",
      "សាលួត: 5.5442\n",
      "ឃុយ: 5.5442\n",
      "អឿង: 5.5442\n",
      "ដូលីន: 5.5442\n",
      "បទិគះ: 5.5442\n",
      "ភេញ: 5.5442\n",
      "យមកៈ: 5.5442\n",
      "រូបរាងៈ: 5.5442\n",
      "រ៉ាដូ: 5.5442\n",
      "បឹងឆ្មារ: 5.5442\n",
      "ហ្សូអ៊ី: 5.5442\n",
      "ភេក្នុង: 5.5442\n",
      "ប៉ូកាសុី: 5.5442\n",
      "ព្រះពុទ្ធញ្ញាណ: 5.5442\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Compute average TF-IDF for each word across corpus\n",
    "def average_tfidf(tfidf_docs):\n",
    "    word_sum = defaultdict(float)\n",
    "    word_count = defaultdict(int)\n",
    "    \n",
    "    for doc in tfidf_docs:\n",
    "        for word, score in doc.items():\n",
    "            word_sum[word] += score\n",
    "            word_count[word] += 1\n",
    "    \n",
    "    avg_tfidf = {w: word_sum[w] / word_count[w] for w in word_sum}\n",
    "    return dict(sorted(avg_tfidf.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "avg_with_sw = average_tfidf(tfidf_docs_with_sw)\n",
    "avg_without_sw = average_tfidf(tfidf_docs_without_sw)\n",
    "\n",
    "# Display top 20 words across corpus\n",
    "print(\"Top 20 words WITH stopwords (corpus-level):\")\n",
    "for w, s in list(avg_with_sw.items())[:20]:\n",
    "    print(f\"{w}: {s:.4f}\")\n",
    "\n",
    "print(\"\\nTop 20 words WITHOUT stopwords (corpus-level):\")\n",
    "for w, s in list(avg_without_sw.items())[:20]:\n",
    "    print(f\"{w}: {s:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69391d3f",
   "metadata": {},
   "source": [
    "##### integrate Khmer stop-word dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e5bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4449b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPWORD_GROUPS = {\n",
    "    \"Conjunctions\",\n",
    "    \"Pronouns\",\n",
    "    \"Determiners & Quantifiers\",\n",
    "    \"Prepositions / Relational Words\",\n",
    "    \"Auxiliary Verbs / Aspect Markers\",\n",
    "    \"Particles & Discourse Markers\",\n",
    "    \"Question & Negation Words\",\n",
    "    \"Function Nouns\",\n",
    "    \"Numbers & Time Expressions\",\n",
    "    \"Politeness & Honorifics\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b69975d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: ['term', 'linguistic_group']\n",
      "Loaded Khmer stopwords: 615\n"
     ]
    }
   ],
   "source": [
    "def load_stopwords_from_annotated_csv(csv_path):\n",
    "    stopwords = set()\n",
    "\n",
    "    with open(csv_path, encoding=\"utf-8-sig\") as f:\n",
    "        reader = csv.DictReader(f, delimiter=\",\")\n",
    "\n",
    "        print(\"Detected columns:\", reader.fieldnames)\n",
    "\n",
    "        for row in reader:\n",
    "            term = row[\"term\"].strip()\n",
    "            group = row[\"linguistic_group\"].strip().lower()\n",
    "\n",
    "            # Remove everything EXCEPT content words\n",
    "            if \"content word\" not in group:\n",
    "                stopwords.add(term)\n",
    "\n",
    "    return stopwords\n",
    "\n",
    "\n",
    "KHMER_STOPWORDS = load_stopwords_from_annotated_csv(\"FIle_Stopwords.csv\")\n",
    "print(\"Loaded Khmer stopwords:\", len(KHMER_STOPWORDS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7854ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'កន្លែងណាមួយ',\n",
       " 'កម្រិត',\n",
       " 'កាន់តែ',\n",
       " 'កាន់តែច្រើន',\n",
       " 'ការជ្រៀតជ្រែក',\n",
       " 'ការបញ្ចប់',\n",
       " 'ការបើកចំហ',\n",
       " 'ការផ្លាស់ប្តូរ',\n",
       " 'ការរៀបចំ',\n",
       " 'ការសម្រេច',\n",
       " 'កាល',\n",
       " 'កាលណា',\n",
       " 'កាលនោះ',\n",
       " 'កាលបើ',\n",
       " 'កាលពី',\n",
       " 'កាលពីមុន',\n",
       " 'កើត',\n",
       " 'កំពុង',\n",
       " 'ក៏',\n",
       " 'ក៏ត្រូវ',\n",
       " 'ក្នុង',\n",
       " 'ក្បែរ',\n",
       " 'ក្បែរនេះ',\n",
       " 'ក្រោម',\n",
       " 'ក្រោយ',\n",
       " 'ខ្លួន',\n",
       " 'គាត់',\n",
       " 'គួរតែ',\n",
       " 'គួរសម',\n",
       " 'គួរឲ្យកត់សម្គាល់',\n",
       " 'គេ',\n",
       " 'គេប៉ុណ្ណោះ',\n",
       " 'គ្មានកន្លែង',\n",
       " 'គ្មាននរណា',\n",
       " 'គ្រប់',\n",
       " 'គ្រប់គ្នា',\n",
       " 'គ្រាន់តែ',\n",
       " 'ឃើញតែ',\n",
       " 'ចង់',\n",
       " 'ចាប់តាំងពី',\n",
       " 'ចុះ',\n",
       " 'ចូល',\n",
       " 'ចូលទៅ',\n",
       " 'ចូលរួម',\n",
       " 'ចេញ',\n",
       " 'ចេញពី',\n",
       " 'ចំណែក',\n",
       " 'ចំណែកឯ',\n",
       " 'ចំនួន',\n",
       " 'ចំនួនច្រើន',\n",
       " 'ចំនួនបន្ថែម',\n",
       " 'ចំពោះ',\n",
       " 'ចំពោះបញ្ហា',\n",
       " 'ច្បាស់ណាស់',\n",
       " 'ច្បាស់លាស់',\n",
       " 'ច្រើន',\n",
       " 'ច្រើនជាងគេ',\n",
       " 'ច្រើនណាស់',\n",
       " 'ឆ្លាស់គ្នា',\n",
       " 'ឆ្លាស់ទៅ',\n",
       " 'ឆ្លើយ',\n",
       " 'ឆ្លើយឆ្លង',\n",
       " 'ឆ្លើយតប',\n",
       " 'ឆ្លៀតកន្លែង',\n",
       " 'ឆ្លៀតការបញ្ចប់',\n",
       " 'ឆ្លៀតគ្នា',\n",
       " 'ឆ្លៀតឃើញ',\n",
       " 'ឆ្លៀតចាប់ផ្តើម',\n",
       " 'ឆ្លៀតចូលរួម',\n",
       " 'ឆ្លៀតចំណេញ',\n",
       " 'ឆ្លៀតចំណែក',\n",
       " 'ឆ្លៀតជាមួយនឹង',\n",
       " 'ឆ្លៀតដាក់',\n",
       " 'ឆ្លៀតតែងតាំង',\n",
       " 'ឆ្លៀតតំរង់',\n",
       " 'ឆ្លៀតត្រូវ',\n",
       " 'ឆ្លៀតទៅ',\n",
       " 'ឆ្លៀតធ្វើ',\n",
       " 'ឆ្លៀតបង្កើត',\n",
       " 'ឆ្លៀតបន្ថែម',\n",
       " 'ឆ្លៀតបើកបង្ហាញ',\n",
       " 'ឆ្លៀតផ្តល់',\n",
       " 'ឆ្លៀតពេល',\n",
       " 'ឆ្លៀតមក',\n",
       " 'ឆ្លៀតយក',\n",
       " 'ឆ្លៀតលេង',\n",
       " 'ឆ្លៀតវេលា',\n",
       " 'ឆ្លៀតសន្ទក',\n",
       " 'ឆ្លៀតសន្ទនា',\n",
       " 'ឆ្លៀតសម័យ',\n",
       " 'ឆ្លៀតសម្រាក',\n",
       " 'ឆ្លៀតសម្លៀកបំពាក់',\n",
       " 'ឆ្លៀតសួរគ្នា',\n",
       " 'ឆ្លៀតអាន',\n",
       " 'ឆ្លៀតអ្វីដែល',\n",
       " 'ជា',\n",
       " 'ជាដរាប',\n",
       " 'ជាថ្មី',\n",
       " 'ជាធម្មតា',\n",
       " 'ជានិច្ច',\n",
       " 'ជាប់នឹង',\n",
       " 'ជាមួយនឹង',\n",
       " 'ជិត',\n",
       " 'ជំរាប',\n",
       " 'ជំរាបសួរ',\n",
       " 'ឈប់',\n",
       " 'ឈប់និយាយ',\n",
       " 'ឈានដល់',\n",
       " 'ឈានទៅ',\n",
       " 'ញែក',\n",
       " 'ដកចេញ',\n",
       " 'ដល់',\n",
       " 'ដល់កន្លែង',\n",
       " 'ដល់ហើយ',\n",
       " 'ដឹងច្បាស់',\n",
       " 'ដឹងត្រូវ',\n",
       " 'ដឹងពី',\n",
       " 'ដឹងហើយ',\n",
       " 'ដឹងហើយឯង',\n",
       " 'ដូច',\n",
       " 'ដូចគ្នា',\n",
       " 'ដូចជា',\n",
       " 'ដូចដែល',\n",
       " 'ដូចទៀង',\n",
       " 'ដូចនេះហើយ',\n",
       " 'ដូចបែបនេះ',\n",
       " 'ដូចរបៀប',\n",
       " 'ដូច្នេះ',\n",
       " 'ដូច្នេះហើយ',\n",
       " 'ដើម្បី',\n",
       " 'ដើម្បីឆ្លើយ',\n",
       " 'ដើម្បីឲ្យ',\n",
       " 'ដើរតួ',\n",
       " 'ដើរទៅ',\n",
       " 'ដែរ',\n",
       " 'ដែរគ្រប់',\n",
       " 'ដែល',\n",
       " 'ដែលជា',\n",
       " 'ដែលនឹង',\n",
       " 'ដែលអាច',\n",
       " 'ដោយសារ',\n",
       " 'ដោះស្រាយ',\n",
       " 'ដំណាក់កាល',\n",
       " 'ដំណឹង',\n",
       " 'ដំណើរ',\n",
       " 'ដំណើរការ',\n",
       " 'ដំណោះស្រាយ',\n",
       " 'ដ៏',\n",
       " 'ណា',\n",
       " 'ណាស់',\n",
       " 'ណាស់ណា',\n",
       " 'តម្លៃ',\n",
       " 'តាម',\n",
       " 'តាមចន្លោះ',\n",
       " 'តាមទំលាប់',\n",
       " 'តាមរយៈ',\n",
       " 'តើ',\n",
       " 'តើធ្វើម្តេច',\n",
       " 'តើនរណា',\n",
       " 'តើបែបណា',\n",
       " 'តើបែបនេះ',\n",
       " 'តើហើយ',\n",
       " 'តើហេតុអ្វី',\n",
       " 'តើអាចយ៉ាងណា',\n",
       " 'តើអ្វី',\n",
       " 'តែ',\n",
       " 'តែប៉ុណ្ណោះ',\n",
       " 'ត្រង់តែ',\n",
       " 'ត្រង់នោះ',\n",
       " 'ត្រលប់វិញ',\n",
       " 'ត្រលះ',\n",
       " 'ត្រឹម',\n",
       " 'ត្រឹមតែ',\n",
       " 'ត្រឹមនោះ',\n",
       " 'ត្រូវជាមួយ',\n",
       " 'ត្រូវតែ',\n",
       " 'ត្រូវបាន',\n",
       " 'ត្រៀម',\n",
       " 'ត្រៀមចេញ',\n",
       " 'ទទួល',\n",
       " 'ទទួលខុសត្រូវ',\n",
       " 'ទទួលយក',\n",
       " 'ទល់នឹង',\n",
       " 'ទស្សនា',\n",
       " 'ទាក់ទង',\n",
       " 'ទាន់',\n",
       " 'ទាន់ពេល',\n",
       " 'ទាស់',\n",
       " 'ទាស់ដាច់',\n",
       " 'ទាំង',\n",
       " 'ទាំងនេះ',\n",
       " 'ទាំងនេះហើយ',\n",
       " 'ទាំងបី',\n",
       " 'ទាំងអស់',\n",
       " 'ទាំងអស់គ្នា',\n",
       " 'ទុក',\n",
       " 'ទុកចិត្ត',\n",
       " 'ទុកសម្រាក',\n",
       " 'ទូទៅដែរ',\n",
       " 'ទូទៅប៉ុន្មាន',\n",
       " 'ទេ',\n",
       " 'ទោះបី',\n",
       " 'ទោះបីជា',\n",
       " 'ទោះបីយ៉ាងណា',\n",
       " 'ទៅកាន់',\n",
       " 'ទៅជាមួយ',\n",
       " 'ទៅជាយ៉ាងណា',\n",
       " 'ទៅជាអ្វី',\n",
       " 'ទៅដល់ទីនោះ',\n",
       " 'ទៅណាក៏ដោយ',\n",
       " 'ទៅបើក',\n",
       " 'ទៅមើល',\n",
       " 'ទៅលើ',\n",
       " 'ទៅលើសទៀត',\n",
       " 'ទៅវិញ',\n",
       " 'ទៅហើយ',\n",
       " 'ទំនងជា',\n",
       " 'ទំនេរ',\n",
       " 'ទំនេរជាប្រការ',\n",
       " 'ធ្លាក់ចុះ',\n",
       " 'ធ្លាក់ទាំងស្រុង',\n",
       " 'ធ្លាប់ជាមុន',\n",
       " 'ធ្លាប់និយាយ',\n",
       " 'ធ្វើការងារ',\n",
       " 'ធ្វើបច្ចុប្បន្នភាព',\n",
       " 'ធ្វើឱ្យ',\n",
       " 'ធ្វើឲ្យទាន់ពេល',\n",
       " 'ធ្វើឲ្យល្អ',\n",
       " 'នរណា',\n",
       " 'នាង',\n",
       " 'និង',\n",
       " 'នឹកចិត្ត',\n",
       " 'នឹកស្មាន',\n",
       " 'នឹកស្រឡាញ់',\n",
       " 'នឹង',\n",
       " 'នឹងកើតឡើង',\n",
       " 'នឹងកំណត់',\n",
       " 'នឹងតែ',\n",
       " 'នឹងត្រូវ',\n",
       " 'នឹងបន្ដិច',\n",
       " 'នឹងអាចធ្វើបាន',\n",
       " 'នូវ',\n",
       " 'នេះ',\n",
       " 'នេះក៏បាន',\n",
       " 'នេះក៏អាច',\n",
       " 'នេះជា',\n",
       " 'នេះតែប៉ុណ្ណោះ',\n",
       " 'នេះត្រូវជា',\n",
       " 'នេះហើយ',\n",
       " 'នៃ',\n",
       " 'នោះ',\n",
       " 'នោះជា',\n",
       " 'នៅកន្លែង',\n",
       " 'នៅចំពោះមុខ',\n",
       " 'នៅជិតតែ',\n",
       " 'នៅតាម',\n",
       " 'នៅតាមកន្លែង',\n",
       " 'នៅតែ',\n",
       " 'នៅទីនោះ',\n",
       " 'នៅមកវិញ',\n",
       " 'នៅមុខគេ',\n",
       " 'នៅឡើយទេ',\n",
       " 'បញ្ចូល',\n",
       " 'បញ្ជាក់',\n",
       " 'បញ្ជាក់ថា',\n",
       " 'បន្តិច',\n",
       " 'បន្ថយ',\n",
       " 'បន្ថែមទៀត',\n",
       " 'បន្ទាប់',\n",
       " 'បន្ទាប់ពី',\n",
       " 'បន្ទាប់ពីនេះ',\n",
       " 'បន្ទាប់មក',\n",
       " 'បាន',\n",
       " 'បើក',\n",
       " 'បើកទ្វារ',\n",
       " 'បើតម្រូវ',\n",
       " 'បើតែប៉ុណ្ណោះ',\n",
       " 'បើត្រូវជា',\n",
       " 'បើមាន',\n",
       " 'បើមិន',\n",
       " 'បំពេញការងារ',\n",
       " 'ប៉ុណ្ណឹងហើយ',\n",
       " 'ប៉ុណ្ណោះ',\n",
       " 'ប៉ុន្តែ',\n",
       " 'ប៉ុន្នឹងក៏បាន',\n",
       " 'ប៉ុន្មានដង',\n",
       " 'ប៉ុន្មានពេលនោះ',\n",
       " 'ប្រកប',\n",
       " 'ប្រកបដោយ',\n",
       " 'ប្រកបដោយភាព',\n",
       " 'ប្រគល់ទៅ',\n",
       " 'ប្រគល់ឲ្យ',\n",
       " 'ប្រតិបត្តិ',\n",
       " 'ប្រសិនបើ',\n",
       " 'ប្រហែល',\n",
       " 'ប្រហែលជា',\n",
       " 'ប្រហែលជាត្រូវ',\n",
       " 'ប្រហែលជាមិន',\n",
       " 'ប្រហែលតែ',\n",
       " 'ប្រាកដ',\n",
       " 'ប្រាកដជាទេ',\n",
       " 'ប្រាកដថា',\n",
       " 'ប្រាកដមែន',\n",
       " 'ប្រាកដហើយ',\n",
       " 'ប្រាក់',\n",
       " 'ប្រាប់ខ្លួនឯង',\n",
       " 'ប្រាប់ទៅ',\n",
       " 'ប្រាំបី',\n",
       " 'ប្រាំបួន',\n",
       " 'ប្រាំពីរ',\n",
       " 'ប្រើប្រាស់',\n",
       " 'ប្រែ',\n",
       " 'ប្រែជាអ្វី',\n",
       " 'ប្រែទៅជាអ្វី',\n",
       " 'ផ្គត់ផ្គង់',\n",
       " 'ផ្គុំពាក្យ',\n",
       " 'ផ្ដល់តម្លៃដល់',\n",
       " 'ផ្ដើមជាមួយ',\n",
       " 'ផ្ដើមពី',\n",
       " 'ផ្ដើមសម្រាប់',\n",
       " 'ផ្តល់កម្រិតខ្ពស់',\n",
       " 'ផ្តល់កាតសន្តិភាព',\n",
       " 'ផ្តល់ការគិតគូរ',\n",
       " 'ផ្តល់ការងាយស្រួល',\n",
       " 'ផ្តល់ការងាយស្រួលយ៉ាងណា',\n",
       " 'ផ្តល់ការងារចេញ',\n",
       " 'ផ្តល់ការងារច្រើន',\n",
       " 'ផ្តល់ការងារអ្នក',\n",
       " 'ផ្តល់ការជូនដំណឹង',\n",
       " 'ផ្តល់ការទំនុកចិត្ត',\n",
       " 'ផ្តល់ការបរិបូរ',\n",
       " 'ផ្តល់ការផ្តោតអារម្មណ៍',\n",
       " 'ផ្តល់ការពន្យល់',\n",
       " 'ផ្តល់ការយល់ព្រម',\n",
       " 'ផ្តល់ការរាប់បញ្ចូល',\n",
       " 'ផ្តល់ការអនុវត្ត',\n",
       " 'ផ្តល់គុណតម្លៃ',\n",
       " 'ផ្តល់គោលបំណង',\n",
       " 'ផ្តល់ចំណែក',\n",
       " 'ផ្តល់ចំត្រូវ',\n",
       " 'ផ្តល់ចំអិន',\n",
       " 'ផ្តល់ជាអ្វី',\n",
       " 'ផ្តល់ជំនួយ',\n",
       " 'ផ្តល់តួនាទី',\n",
       " 'ផ្តល់ទំនុកចិត្តក្នុង',\n",
       " 'ផ្តល់ទំព័រ',\n",
       " 'ផ្តល់ទ្រទ្រង់',\n",
       " 'ផ្តល់នូវ',\n",
       " 'ផ្តល់នូវសេចក្តីឆ្លើយ',\n",
       " 'ផ្តល់បច្ចេកវិទ្យា',\n",
       " 'ផ្តល់បញ្ជូនគ្នា',\n",
       " 'ផ្តល់ផ្នែក',\n",
       " 'ផ្តល់ពេលវេលាឲ្យគ្នា',\n",
       " 'ផ្តល់ភាពងាយស្រួល',\n",
       " 'ផ្តល់ភាពជឿជាក់',\n",
       " 'ផ្តល់ភាពជោគជ័យ',\n",
       " 'ផ្តល់ភាពល្អ',\n",
       " 'ផ្តល់ភាពសំរាប់',\n",
       " 'ផ្តល់មុខងារចូល',\n",
       " 'ផ្តល់មេរៀន',\n",
       " 'ផ្តល់សិទ្ធិចូលរួម',\n",
       " 'ផ្តល់សុខភាពនិងសន្តិភាព',\n",
       " 'ផ្តល់សេចក្ដីណែនាំ',\n",
       " 'ផ្តល់សេចក្ដីពេញចិត្ត',\n",
       " 'ផ្តល់សេចក្តីព្រាង',\n",
       " 'ផ្តល់អត្តន័យ',\n",
       " 'ផ្តល់អត្ថន័យ',\n",
       " 'ផ្តល់អាការៈ',\n",
       " 'ផ្តល់អានុភាព',\n",
       " 'ផ្តល់អារម្មណ៍ដល់គ្នា',\n",
       " 'ផ្តល់អាហារូបករណ៍',\n",
       " 'ផ្តល់អំណោយ',\n",
       " 'ផ្តល់ឲ្យនរណាម្នាក់',\n",
       " 'ផ្ទាល់',\n",
       " 'ផ្ទាល់ខ្លួន',\n",
       " 'ផ្ទុយ',\n",
       " 'ផ្ទុយនឹង',\n",
       " 'ផ្ទុយពី',\n",
       " 'ផ្លាស់ប្ដូរជាច្រើន',\n",
       " 'ផ្លាស់ប្ដូរតាមពេលវេលា',\n",
       " 'ផ្លាស់ប្ដូរត្រឹមត្រូវ',\n",
       " 'ផ្លាស់ប្ដូរនិស្ស័យ',\n",
       " 'ផ្លាស់ប្ដូរពេលវេលា',\n",
       " 'ផ្លាស់ប្ដូរសម័យ',\n",
       " 'ពី',\n",
       " 'ពីព្រោះ',\n",
       " 'ពុំទាន់',\n",
       " 'ពុំមាន',\n",
       " 'ពេញចិត្ត',\n",
       " 'ពេញមួយថ្ងៃ',\n",
       " 'ពេញល្បង',\n",
       " 'ពេល',\n",
       " 'ពេលដែលកន្លង',\n",
       " 'ពេលដែលឆាប់',\n",
       " 'ពេលដែលត្រូវ',\n",
       " 'ពេលដែលមាន',\n",
       " 'ពេលដែលអាច',\n",
       " 'ពេលណា',\n",
       " 'ពេលណានោះហើយ',\n",
       " 'ពេលណាមិញ',\n",
       " 'ពេលណាមិញទេ',\n",
       " 'ពេលណាមិនទាន់',\n",
       " 'ពេលណាមួយ',\n",
       " 'ពេលណាមួយក៏បាន',\n",
       " 'ពេលនេះ',\n",
       " 'ពេលនេះហើយ',\n",
       " 'ពេលវេលាខ្លះ',\n",
       " 'ពេលវេលាច្រើន',\n",
       " 'ពេលវេលាដែល',\n",
       " 'ពេលវេលាប៉ុណ្ណោះ',\n",
       " 'ពោលគឺ',\n",
       " 'ពោលទៅ',\n",
       " 'ព្យាបាទច្រើនណាស់',\n",
       " 'ព្យាយាមតែប៉ុណ្ណោះ',\n",
       " 'ព្យាយាមយ៉ាងខ្លាំង',\n",
       " 'ព្រមទទួល',\n",
       " 'ព្រមទាំង',\n",
       " 'ព្រមសន្មត់',\n",
       " 'ព្រាត់ចិត្ត',\n",
       " 'ព្រួយ',\n",
       " 'ព្រោះតែ',\n",
       " 'ព្រោះតែវា',\n",
       " 'ព្រោះថា',\n",
       " 'ព្រោះថាអ្នក',\n",
       " 'ព្រោះហេតុនេះ',\n",
       " 'ព្រោះអញ្ចឹង',\n",
       " 'ភាគណា',\n",
       " 'ភាគបន្ថែម',\n",
       " 'ភាគពេញ',\n",
       " 'ភាគរយ',\n",
       " 'ភ្លឺ',\n",
       " 'ភ្លេចចង់',\n",
       " 'ភ្លេចឆ្លើយ',\n",
       " 'ភ្លេចដល់',\n",
       " 'ភ្លេចត្រូវ',\n",
       " 'ភ្លេចទៅ',\n",
       " 'ភ្លេចទៅវិញ',\n",
       " 'ភ្លេចបញ្ជាក់',\n",
       " 'ភ្លេចមិនបាន',\n",
       " 'ភ្លេចយក',\n",
       " 'ភ្លេចសុំព្យាបាល',\n",
       " 'ភ្លេចសូម្បីតែ',\n",
       " 'ភ្លេចសំខាន់',\n",
       " 'ភ្លេចស្នាម',\n",
       " 'ភ្លេចស្រឡាញ់',\n",
       " 'ភ្លេចហើយឯង',\n",
       " 'ភ្លេចអស់',\n",
       " 'ភ្លេចអ្វី',\n",
       " 'មាន',\n",
       " 'មិន',\n",
       " 'មិនខុស',\n",
       " 'មិនគិត',\n",
       " 'មិនគួរមើល',\n",
       " 'មិនឃើញ',\n",
       " 'មិនឃើញខុសគ្នា',\n",
       " 'មិនឃើញស្រួល',\n",
       " 'មិនងាយ',\n",
       " 'មិនងាយស្រួល',\n",
       " 'មិនចង់',\n",
       " 'មិនចាំបាច់',\n",
       " 'មិនច្បាស់',\n",
       " 'មិនជាក់',\n",
       " 'មិនជឿ',\n",
       " 'មិនដឹង',\n",
       " 'មិនត្រឹមតែ',\n",
       " 'មិនត្រឹមត្រូវ',\n",
       " 'មិនត្រូវការ',\n",
       " 'មិនត្រូវនិយាយ',\n",
       " 'មិនទទួល',\n",
       " 'មិនទាក់ទង',\n",
       " 'មិនទាន់',\n",
       " 'មិនទាន់ឃើញ',\n",
       " 'មិនទាន់ចប់',\n",
       " 'មិនទាន់ច្បាស់',\n",
       " 'មិនទាន់ដឹង',\n",
       " 'មិនទាន់ត្រូវ',\n",
       " 'មិនទាន់បាន',\n",
       " 'មិនទាន់បានទេ',\n",
       " 'មិនទាន់ល្អ',\n",
       " 'មិនទាន់អាច',\n",
       " 'មិនទំនេរ',\n",
       " 'មិនបង្ហាញ',\n",
       " 'មិនបញ្ចូល',\n",
       " 'មិនបន្ថែម',\n",
       " 'មិនបាច់',\n",
       " 'មិនបាច់ខ្លាំង',\n",
       " 'មិនបាច់ឃើញ',\n",
       " 'មិនបាច់ទាំងអស់',\n",
       " 'មិនបាច់បន្ថែម',\n",
       " 'មិនបាច់ព្រួយ',\n",
       " 'មិនបាន',\n",
       " 'មិនបានច្បាស់',\n",
       " 'មិនបានត្រឹមតែ',\n",
       " 'មិនបាននិយាយតែ',\n",
       " 'មិនបានលើកឡើង',\n",
       " 'មិនបានស្រួល',\n",
       " 'មិនព្រមទទួល',\n",
       " 'មិនព្រមទេ',\n",
       " 'មិនមាន',\n",
       " 'មិនមើលឃើញ',\n",
       " 'មិនមែន',\n",
       " 'មិនមែនទេ',\n",
       " 'មិនលើកលែង',\n",
       " 'មិនសម្ដែង',\n",
       " 'មិនសូវ',\n",
       " 'មិនសូវនិយាយ',\n",
       " 'មិនសំខាន់',\n",
       " 'មិនស្រប',\n",
       " 'មិនស្រលាញ់',\n",
       " 'មិនស្អិត',\n",
       " 'មិនស្អិតជាប់',\n",
       " 'មិនអនុញ្ញាត',\n",
       " 'មិនអស់សំណើច',\n",
       " 'មិនអាច',\n",
       " 'មិនអើពើ',\n",
       " 'មិនឲ្យ',\n",
       " 'មិនឲ្យសង្ឃឹម',\n",
       " 'មុខ',\n",
       " 'មួយ',\n",
       " 'មួយចំនួន',\n",
       " 'មួយឆ្នាំ',\n",
       " 'មួយទៀត',\n",
       " 'មួយភ្លែត',\n",
       " 'មែន',\n",
       " 'មែនទេ',\n",
       " 'មែនទែន',\n",
       " 'ម្នាក់',\n",
       " 'ម្នាក់ឯង',\n",
       " 'ម្យ៉ាងទៀត',\n",
       " 'យើង',\n",
       " 'យើងខ្ញុំ',\n",
       " 'យើងទាំងអស់',\n",
       " 'យ៉ាង',\n",
       " 'យ៉ាងខ្លាំង',\n",
       " 'យ៉ាងណា',\n",
       " 'យ៉ាងណាក៏ដោយ',\n",
       " 'យ៉ាងណាមិញ',\n",
       " 'របស់',\n",
       " 'របស់ខ្ញុំ',\n",
       " 'របស់គាត់',\n",
       " 'របស់នាង',\n",
       " 'របស់ពួកគេ',\n",
       " 'រហូត',\n",
       " 'រហូតដល់',\n",
       " 'រហូតទៅដល់',\n",
       " 'រីឯ',\n",
       " 'រឺក៏',\n",
       " 'រួមទាំង',\n",
       " 'លើ',\n",
       " 'លើកលែង',\n",
       " 'លោក',\n",
       " 'ល្អ',\n",
       " 'ល្អណាស់',\n",
       " 'ល្អបំផុត',\n",
       " 'វា',\n",
       " 'សព្វ',\n",
       " 'សព្វពេល',\n",
       " 'សម្រាប់',\n",
       " 'សរុបមក',\n",
       " 'សុទ្ធតែ',\n",
       " 'សូម',\n",
       " 'សូមជ្រាប',\n",
       " 'សូមទន្ទឹង',\n",
       " 'សូមទោស',\n",
       " 'សូមធ្វើ',\n",
       " 'សូមបញ្ជាក់',\n",
       " 'សូមប្រាប់',\n",
       " 'សូមពិនិត្យ',\n",
       " 'សូមព្យាបាល',\n",
       " 'សូមរង់ចាំ',\n",
       " 'សូមស្វាគមន៍',\n",
       " 'សូមឲ្យ',\n",
       " 'សោះ',\n",
       " 'សំរាប់',\n",
       " 'ស្គាល់',\n",
       " 'ស្ទើរតែ',\n",
       " 'ហាក់ដូចជា',\n",
       " 'ហាក់ទំនេរ',\n",
       " 'ហាក់នៅ',\n",
       " 'ហាក់បង្កប់',\n",
       " 'ហាក់បង្កើន',\n",
       " 'ហាក់បង្ហាញ',\n",
       " 'ហាក់បាក់',\n",
       " 'ហាក់បីដូចជា',\n",
       " 'ហាក់បីដូចម្តេច',\n",
       " 'ហាក់បែបនោះ',\n",
       " 'ហាក់មាន',\n",
       " 'ហើយ',\n",
       " 'ហើយត្រូវ',\n",
       " 'ហើយនឹង',\n",
       " 'ហេតុនេះ',\n",
       " 'ហេតុនេះហើយ',\n",
       " 'ហេតុអ្វី',\n",
       " 'ហ្នឹង',\n",
       " 'ឡើង',\n",
       " 'អញ្ចឹង',\n",
       " 'អត់',\n",
       " 'អាច',\n",
       " 'អាចជា',\n",
       " 'អាចនឹង',\n",
       " 'អំពី',\n",
       " 'អ៊ីចឹង',\n",
       " 'អ្នក',\n",
       " 'អ្នកណា',\n",
       " 'អ្នកទាំងអស់',\n",
       " 'អ្វី',\n",
       " 'អ្វីខ្លះ',\n",
       " 'អ្វីដែល',\n",
       " 'អ្វីៗ',\n",
       " 'ឥតឈប់ឈរ',\n",
       " 'ឥឡូវ',\n",
       " 'ឥឡូវនេះ',\n",
       " 'ឯ',\n",
       " 'ឯង',\n",
       " 'ឱកាស'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KHMER_STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c76062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords from tokenized docs\n",
    "\n",
    "def remove_stopwords(tokenized_docs, stopwords):\n",
    "    \"\"\"Return tokenized documents with stopwords removed\"\"\"\n",
    "    return [[w for w in doc if w not in stopwords] for doc in tokenized_docs]\n",
    "\n",
    "tokenized_docs_refined = remove_stopwords(tokenized_docs_with_sw, KHMER_STOPWORDS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52fe5787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute TF, IDF, TF-IDF for refined docs\n",
    "\n",
    "tf_docs_refined = [compute_tf(doc) for doc in tokenized_docs_refined]\n",
    "idf_refined = compute_idf_fast(tokenized_docs_refined)\n",
    "tfidf_docs_refined = [compute_tfidf(tf, idf_refined) for tf in tf_docs_refined]\n",
    "\n",
    "avg_refined = average_tfidf(tfidf_docs_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67d8c43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 words WITH original stopwords\n",
      "ឯកច្ឆន្ច: 6.6530\n",
      "អសុពលភាព: 6.6530\n",
      "ហ្សូអ៊ី: 5.5442\n",
      "គតេ: 4.4353\n",
      "ឣនុធម្មចារី: 3.6961\n",
      "វេទព្វជាតក: 3.6961\n",
      "កិម្បក្កជាតក: 3.6961\n",
      "សុទ្ធ់: 3.6961\n",
      "សីហធម្មជាតក: 3.6961\n",
      "កន្ថរ៉ា: 3.6961\n",
      "ហ្វហ: 3.6961\n",
      "វានរជាតក: 3.6961\n",
      "បច្ចុប្បន្នៈ: 3.6961\n",
      "ចូច: 3.6961\n",
      "ពុទ្ធារី: 3.6961\n",
      "វីតា: 3.6961\n",
      "ឧទាយិវគ្គ: 3.6961\n",
      "អត្ថទ: 3.6961\n",
      "ព្រះតន្តិ: 3.6961\n",
      "ព្រះតន្តី: 3.6961\n",
      "\n",
      "Top 20 words WITHOUT initial stopwords\n",
      "អសុពលភាព: 11.0883\n",
      "ប្រូតូកាទុ: 11.0883\n",
      "ត្រូវៈ: 11.0883\n",
      "ឯកច្ឆន្ច: 8.3162\n",
      "អ្នកសង្កេតឃើញ: 5.5442\n",
      "ទៅកាន់ខ្សែភាពយន្ត: 5.5442\n",
      "សាលួត: 5.5442\n",
      "ឃុយ: 5.5442\n",
      "អឿង: 5.5442\n",
      "ដូលីន: 5.5442\n",
      "បទិគះ: 5.5442\n",
      "ភេញ: 5.5442\n",
      "យមកៈ: 5.5442\n",
      "រូបរាងៈ: 5.5442\n",
      "រ៉ាដូ: 5.5442\n",
      "បឹងឆ្មារ: 5.5442\n",
      "ហ្សូអ៊ី: 5.5442\n",
      "ភេក្នុង: 5.5442\n",
      "ប៉ូកាសុី: 5.5442\n",
      "ព្រះពុទ្ធញ្ញាណ: 5.5442\n",
      "\n",
      "Top 20 words AFTER applying Khmer stopword list\n",
      "អសុពលភាព: 11.0883\n",
      "ប្រូតូកាទុ: 11.0883\n",
      "ឯកច្ឆន្ច: 8.3162\n",
      "សាលួត: 5.5442\n",
      "ឃុយ: 5.5442\n",
      "អឿង: 5.5442\n",
      "ដូលីន: 5.5442\n",
      "បទិគះ: 5.5442\n",
      "យមកៈ: 5.5442\n",
      "រូបរាងៈ: 5.5442\n",
      "រ៉ាដូ: 5.5442\n",
      "បឹងឆ្មារ: 5.5442\n",
      "ហ្សូអ៊ី: 5.5442\n",
      "ប៉ូកាសុី: 5.5442\n",
      "ធម្មខក្ខន្ធ: 5.5442\n",
      "គីស៊ុន: 5.5442\n",
      "កកសស: 5.5442\n",
      "បរិប័ន្ន: 4.7521\n",
      "គតេ: 4.4353\n",
      "ព្រះព្រហ្មាធិរាជ: 3.6961\n"
     ]
    }
   ],
   "source": [
    "# Display comparison\n",
    "\n",
    "def print_top_words(title, avg_tfidf, top_n=20):\n",
    "    print(f\"\\n{title}\")\n",
    "    for w, s in list(avg_tfidf.items())[:top_n]:\n",
    "        print(f\"{w}: {s:.4f}\")\n",
    "\n",
    "print_top_words(\"Top 20 words WITH original stopwords\", avg_with_sw)\n",
    "print_top_words(\"Top 20 words WITHOUT initial stopwords\", avg_without_sw)\n",
    "print_top_words(\"Top 20 words AFTER applying Khmer stopword list\", avg_refined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a0d8b",
   "metadata": {},
   "source": [
    "The TF-IDF computation highlights the most statistically significant words in the corpus. As expected, the top TF-IDF words are content words, proper nouns, or domain-specific terms rather than grammatical stopwords (ex: អសុពលភាព, ប្រូតូកាទុ), because true stopwords appear in almost all documents, giving them very low IDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63d5d805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Candidate stopwords to consider adding (manual review):\n",
      "['អសុពលភាព', 'ប្រូតូកាទុ', 'ឯកច្ឆន្ច', 'សាលួត', 'ឃុយ', 'អឿង', 'ដូលីន', 'បទិគះ', 'យមកៈ', 'រូបរាងៈ', 'រ៉ាដូ', 'បឹងឆ្មារ', 'ហ្សូអ៊ី', 'ប៉ូកាសុី', 'ធម្មខក្ខន្ធ', 'គីស៊ុន', 'កកសស', 'បរិប័ន្ន', 'គតេ', 'ព្រះព្រហ្មាធិរាជ', 'ព្រងិល', 'ឣនុបាទិយានោ', 'ឣនុធម្មចារី', 'វេទព្វជាតក', 'កិម្បក្កជាតក', 'សុទ្ធ់', 'សីហធម្មជាតក', 'បច្ចេកវិ', 'កន្ថរ៉ា', 'ហ្វហ', 'ហ្គ្រីឡូ', 'សទ្ទកម្ម', 'វានរជាតក', 'ប្រវត្តិការងារ', 'បច្ចុប្បន្នៈ', 'អ្នកសង្កេតឃើញ', 'ដើជ្រៃ', 'ចូច', 'ពុទ្ធារី', 'វីតា', 'ឧទាយិវគ្គ', 'អត្ថទ', 'ព្រះតន្តិ', 'ព្រះតន្តី', 'ទៅកាន់ខ្សែភាពយន្ត', 'ដារ៉', 'ម៉ាញ់', 'ឡឿក', 'បាពហុ', 'សន្ធាយ']\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Suggest candidate stopwords (optional)\n",
    "# Words still high in TF-IDF but not content words\n",
    "\n",
    "top_candidates = [w for w, s in list(avg_refined.items())[:50]]  # top 50\n",
    "print(\"\\nCandidate stopwords to consider adding (manual review):\")\n",
    "print(top_candidates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac6e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate stopwords (from WITH original stopwords):\n",
      "[]\n",
      "\n",
      "Candidate stopwords (from WITHOUT initial stopwords):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def suggest_candidate_stopwords(tfidf_docs, top_n=50, min_doc_ratio=0.01):\n",
    "#     \"\"\"\n",
    "#     Suggest candidate stopwords based on:\n",
    "#     - Top N words by average TF-IDF\n",
    "#     - Appear in at least `min_doc_ratio` fraction of documents\n",
    "#     \"\"\"\n",
    "#     N_docs = len(tfidf_docs)\n",
    "    \n",
    "#     # Compute average TF-IDF\n",
    "#     avg_tfidf = average_tfidf(tfidf_docs)\n",
    "    \n",
    "#     # Take top N words\n",
    "#     top_words = list(avg_tfidf.keys())[:top_n]\n",
    "    \n",
    "#     # Count in how many documents each word appears\n",
    "#     word_doc_count = Counter()\n",
    "#     for doc in tfidf_docs:\n",
    "#         for word in doc:\n",
    "#             if word in top_words:\n",
    "#                 word_doc_count[word] += 1\n",
    "    \n",
    "#     # Filter by document frequency ratio\n",
    "#     candidates = [word for word, count in word_doc_count.items() if count / N_docs >= min_doc_ratio]\n",
    "#     return candidates\n",
    "\n",
    "# # Example\n",
    "# candidate_stopwords_with_sw = suggest_candidate_stopwords(tfidf_docs_with_sw, top_n=50, min_doc_ratio=0.01)\n",
    "# candidate_stopwords_without_sw = suggest_candidate_stopwords(tfidf_docs_without_sw, top_n=50, min_doc_ratio=0.01)\n",
    "\n",
    "# print(\"Candidate stopwords (from WITH original stopwords):\")\n",
    "# print(candidate_stopwords_with_sw)\n",
    "\n",
    "# print(\"\\nCandidate stopwords (from WITHOUT initial stopwords):\")\n",
    "# print(candidate_stopwords_without_sw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e93ddc",
   "metadata": {},
   "source": [
    "###### Simple IR Model Using TF-IDF and Top-K Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "283d47a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 similar documents WITH stopwords:\n",
      "[(0, 1.0000000000000002), (20044, 0.3732776475978078), (39001, 0.3665936743440593), (83277, 0.35764972611312484), (62285, 0.3469664539784011)]\n",
      "\n",
      "Top 5 similar documents WITHOUT stopwords:\n",
      "[(0, 0.9036564461309989), (20044, 0.3591125468901498), (116781, 0.3560611253905191), (62285, 0.354057607202223), (83277, 0.3520607628912101)]\n",
      "\n",
      "Overlap in Top-5 documents: 4 / 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two sparse TF-IDF dicts\"\"\"\n",
    "    common_words = set(vec1.keys()) & set(vec2.keys())\n",
    "    num = sum(vec1[w] * vec2[w] for w in common_words)\n",
    "    denom = (np.sqrt(sum(v**2 for v in vec1.values())) * \n",
    "             np.sqrt(sum(v**2 for v in vec2.values())))\n",
    "    return num / denom if denom != 0 else 0\n",
    "\n",
    "def rank_documents(query_vec, tfidf_docs, top_k=5):\n",
    "    \"\"\"Return top K document indices ranked by similarity\"\"\"\n",
    "    scores = [(i, cosine_similarity(query_vec, doc)) for i, doc in enumerate(tfidf_docs)]\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:top_k]\n",
    "\n",
    "# Example: use first document as query\n",
    "query_doc = tfidf_docs_with_sw[0]\n",
    "\n",
    "top_k_with_sw = rank_documents(query_doc, tfidf_docs_with_sw, top_k=5)\n",
    "top_k_without_sw = rank_documents(query_doc, tfidf_docs_without_sw, top_k=5)\n",
    "\n",
    "print(\"Top 5 similar documents WITH stopwords:\")\n",
    "print(top_k_with_sw)\n",
    "\n",
    "print(\"\\nTop 5 similar documents WITHOUT stopwords:\")\n",
    "print(top_k_without_sw)\n",
    "\n",
    "# Compare overlap\n",
    "indices_with_sw = set(idx for idx, _ in top_k_with_sw)\n",
    "indices_without_sw = set(idx for idx, _ in top_k_without_sw)\n",
    "overlap = indices_with_sw & indices_without_sw\n",
    "print(f\"\\nOverlap in Top-5 documents: {len(overlap)} / 5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce66ba",
   "metadata": {},
   "source": [
    "We tested the impact of stopword removal on a TF-IDF based IR model. The Top-5 document retrieval using cosine similarity showed 4/5 overlap between with and without stopwords, indicating that removing stopwords slightly changed the ranking. \n",
    "\n",
    "This confirms that the Khmer stopword removal helps reduce noise without significantly impacting the retrieval of relevant documents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
